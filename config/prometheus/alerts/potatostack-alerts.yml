groups:
  - name: PotatoStack Critical Infrastructure
    interval: 30s
    rules:
      - alert: CriticalServiceDown
        expr: time() - container_last_seen{container_label_potatostack_alerts="critical"} > 120
        for: 2m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "ðŸš¨ Critical service DOWN: {{ $labels.container_label_com_docker_compose_service }}"
          description: "Service {{ $labels.container_label_com_docker_compose_service }} has not been seen for > 2 minutes. This may indicate the container has crashed or stopped."
          runbook: "Check container logs: docker logs {{ $labels.container_label_com_docker_compose_service }}"

      - alert: ContainerCrashLooping
        expr: increase(container_last_seen{name=~".+"}[5m]) > 10
        for: 2m
        labels:
          severity: critical
          component: docker
        annotations:
          summary: "ðŸ”„ Container crash loop: {{ $labels.name }}"
          description: "Container {{ $labels.name }} has restarted > 10 times in 5 minutes. Check logs for errors."
          runbook: "View logs: docker logs -f {{ $labels.name }}"

      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes{name=~".+"} / container_spec_memory_limit_bytes{name=~".+"}) * 100 > 90
        for: 5m
        labels:
          severity: warning
          component: resources
        annotations:
          summary: "âš ï¸ High memory: {{ $labels.name }} ({{ $value | humanizePercentage }})"
          description: "Container {{ $labels.name }} is using > 90% of its memory limit. Consider increasing limits or investigating memory leaks."

      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total{name=~".+"}[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          component: resources
        annotations:
          summary: "âš¡ High CPU: {{ $labels.name }} ({{ $value | humanizePercentage }})"
          description: "Container {{ $labels.name }} has sustained CPU usage > 80% for 10 minutes. Check for infinite loops or heavy computations."

      - alert: ContainerNotRunning
        expr: container_state_running{name=~".+"} == 0
        for: 2m
        labels:
          severity: critical
          component: docker
        annotations:
          summary: "ðŸ›‘ Container not running: {{ $labels.name }}"
          description: "Container {{ $labels.name }} is not in running state. Status may be exited, paused, or dead."

  - name: Database Health
    interval: 60s
    rules:
      - alert: PostgresDown
        expr: pg_up == 0
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "ðŸ—„ï¸ PostgreSQL DOWN"
          description: "PostgreSQL database is unreachable or down. Check container status: docker ps | grep postgres"
          runbook: "Restart if needed: docker restart postgres"

      - alert: PostgresSlowQueries
        expr: rate(pg_stat_statements_calls_total[5m]) > 100
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "ðŸŒ PostgreSQL slow queries detected"
          description: "PostgreSQL is experiencing slow query rates ({{ $value }} calls/sec). Consider indexing or query optimization."

      - alert: PostgresConnectionsHigh
        expr: pg_stat_database_numbackends{datname="postgres"} > 80
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "ðŸ“Š PostgreSQL connections high: {{ $value }}"
          description: "PostgreSQL connection pool is at {{ $value }}% capacity. Check for connection leaks."

      - alert: RedisDown
        expr: redis_up == 0
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "ðŸ”´ Redis DOWN"
          description: "Redis cache is unreachable or down. Check container: docker ps | grep redis"
          runbook: "Restart if needed: docker restart redis-cache"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "ðŸ’¾ Redis memory high: {{ $value | humanizePercentage }}"
          description: "Redis is using > 90% of max memory. May trigger eviction soon."

      - alert: MongoDown
        expr: mongodb_up == 0
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "ðŸŸ¢ MongoDB DOWN"
          description: "MongoDB is unreachable or down. Check container: docker ps | grep mongo"
          runbook: "Restart if needed: docker restart mongo"

      - alert: MongoConnectionsHigh
        expr: mongodb_connections{state="current"} > 800
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "ðŸ“ˆ MongoDB connections high: {{ $value }}"
          description: "MongoDB has {{ $value }} active connections. Check for connection leaks."

  - name: System Health
    interval: 60s
    rules:
      - alert: DiskSpaceCritical
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
          component: storage
        annotations:
          summary: "ðŸ’¥ CRITICAL disk space: {{ $value | humanizePercentage }}"
          description: "Root partition has < 10% space remaining. Immediate action required to prevent system failure."
          runbook: "Run: df -h && docker system prune -a --volumes"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 20
        for: 10m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "âš ï¸ Low disk space: {{ $value | humanizePercentage }}"
          description: "Root partition has < 20% space remaining. Clean up old logs, images, or data."

      - alert: DiskIOHigh
        expr: rate(node_disk_io_time_seconds_total[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "ðŸ’¿ High disk I/O: {{ $value | humanizePercentage }}"
          description: "Disk I/O utilization is > 80% for 10 minutes. May indicate heavy read/write operations."

      - alert: HighLoadAverage
        expr: node_load15 / node_num_cpu > 2
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "ðŸ“Š High system load: {{ $value }}x CPU"
          description: "15-minute load average is 2x CPU cores. System is under heavy load."

      - alert: OutOfMemoryRisk
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 < 5
        for: 5m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "â›” Out of memory risk: {{ $value | humanizePercentage }} available"
          description: "System has < 5% memory available. OOM killer may trigger. Close unnecessary processes or increase swap."

      - alert: NetworkHighLatency
        expr: rate(node_netstat_Tcp_CurrEstab[5m]) > 1000
        for: 5m
        labels:
          severity: warning
          component: network
        annotations:
          summary: "ðŸŒ High network connections: {{ $value }}"
          description: "System has {{ $value }} established TCP connections. Check for unusual network activity."

  - name: Security & Ingress
    interval: 60s
    rules:
      - alert: TraefikDown
        expr: up{job="traefik"} == 0
        for: 2m
        labels:
          severity: critical
          component: ingress
        annotations:
          summary: "ðŸŒ Traefik DOWN - All services inaccessible!"
          description: "Traefik reverse proxy is down. All HTTPS routes are inaccessible. Check: docker logs traefik"
          runbook: "Restart: docker restart traefik"

      - alert: TraefikHighErrorRate
        expr: rate(traefik_service_requests_total{status_code=~"5.."}[5m]) / rate(traefik_service_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          component: ingress
        annotations:
          summary: "âŒ Traefik 5xx errors: {{ $value | humanizePercentage }}"
          description: "Traefik is experiencing > 5% server errors. Check upstream service health and logs."

      - alert: CrowdSecDown
        expr: up{job="crowdsec"} == 0
        for: 2m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "ðŸ›¡ï¸ CrowdSec DOWN - No intrusion protection!"
          description: "CrowdSec IPS is down. System is unprotected against attacks. Restart immediately."
          runbook: "Restart: docker restart crowdsec"

      - alert: HighAttackRate
        expr: rate(crowdsec_decisions_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "âš”ï¸ Attack rate high: {{ $value }}/sec"
          description: "CrowdSec is blocking {{ $value }} attacks per second. Verify legitimate traffic isn't blocked."

  - name: VPN & Networking
    interval: 60s
    rules:
      - alert: GluetunDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="gluetun"} > 120
        for: 2m
        labels:
          severity: critical
          component: vpn
        annotations:
          summary: "ðŸ”Œ VPN DOWN: Gluetun container missing"
          description: "Gluetun VPN container is not running. All VPN-dependent services may be exposed."
          runbook: "Restart: docker restart gluetun"

  - name: slskd Health
    interval: 60s
    rules:
      - alert: SlskdMetricsDown
        expr: up{job="slskd"} == 0
        for: 2m
        labels:
          severity: critical
          component: media
        annotations:
          summary: "ðŸŽ§ slskd metrics DOWN"
          description: "Prometheus cannot scrape slskd metrics at gluetun:2234/metrics for > 2 minutes."
          runbook: "Check: docker logs slskd && docker logs gluetun"

      - alert: SlskdContainerNotSeen
        expr: time() - container_last_seen{container_label_com_docker_compose_service="slskd"} > 120
        for: 2m
        labels:
          severity: critical
          component: media
        annotations:
          summary: "ðŸŽ§ slskd container not seen"
          description: "slskd has not been seen for > 2 minutes. Container may be stopped or unhealthy."
          runbook: "Check: docker ps | grep slskd"

  - name: Media Managers Health
    interval: 60s
    rules:
      - alert: SonarrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="sonarr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸ“º Sonarr DOWN"
          description: "Sonarr TV manager container has not been seen for > 2 minutes."
          runbook: "Check: docker logs sonarr"

      - alert: RadarrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="radarr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸŽ¬ Radarr DOWN"
          description: "Radarr movie manager container has not been seen for > 2 minutes."
          runbook: "Check: docker logs radarr"

      - alert: ProwlarrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="prowlarr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸ” Prowlarr DOWN"
          description: "Prowlarr indexer manager container has not been seen for > 2 minutes."
          runbook: "Check: docker logs prowlarr"

      - alert: LidarrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="lidarr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸŽµ Lidarr DOWN"
          description: "Lidarr music manager container has not been seen for > 2 minutes."
          runbook: "Check: docker logs lidarr"

      - alert: BazarrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="bazarr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸ’¬ Bazarr DOWN"
          description: "Bazarr subtitle manager container has not been seen for > 2 minutes."
          runbook: "Check: docker logs bazarr"

  - name: Media Server Health
    interval: 60s
    rules:
      - alert: JellyfinDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="jellyfin"} > 120
        for: 2m
        labels:
          severity: critical
          component: media
        annotations:
          summary: "ðŸŽ¬ Jellyfin DOWN - Media server inaccessible!"
          description: "Jellyfin media server container has not been seen for > 2 minutes. Media playback will be affected."
          runbook: "Check: docker logs jellyfin"

      - alert: JellyfinHighCPU
        expr: rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_service="jellyfin"}[5m]) > 0.8
        for: 15m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "âš¡ Jellyfin high CPU usage"
          description: "Jellyfin has sustained CPU usage > 80% for 15 minutes. Consider hardware acceleration or reduce transcoding."

      - alert: JellyseerrDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="jellyseerr"} > 120
        for: 2m
        labels:
          severity: warning
          component: media
        annotations:
          summary: "ðŸ“‹ Jellyseerr DOWN"
          description: "Jellyseerr media request service container has not been seen for > 2 minutes."
          runbook: "Check: docker logs jellyseerr"

  - name: RSS Reader Health
    interval: 60s
    rules:
      - alert: MinifluxDown
        expr: up{job="miniflux"} == 0
        for: 2m
        labels:
          severity: warning
          component: tools
        annotations:
          summary: "ðŸ“° Miniflux DOWN"
          description: "Miniflux RSS reader metrics endpoint is unreachable. Container may be down."
          runbook: "Check: docker logs miniflux"

  - name: Uptime Monitoring
    interval: 60s
    rules:
      - alert: UptimeKumaDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="uptime-kuma"} > 120
        for: 2m
        labels:
          severity: critical
          component: monitoring
        annotations:
          summary: "ðŸ“Š Uptime Kuma DOWN"
          description: "Uptime Kuma monitoring service container has not been seen for > 2 minutes."
          runbook: "Check: docker logs uptime-kuma"

      - alert: HealthchecksDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="healthchecks"} > 120
        for: 2m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "âœ… Healthchecks DOWN"
          description: "Healthchecks cron monitoring service container has not been seen for > 2 minutes."
          runbook: "Check: docker logs healthchecks"

  - name: Backup & Storage Services
    interval: 60s
    rules:
      - alert: ScrutinyDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="scrutiny"} > 120
        for: 2m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "ðŸ” Scrutiny DOWN"
          description: "Scrutiny disk health monitoring container has not been seen for > 2 minutes."
          runbook: "Check: docker logs scrutiny"

  - name: CI/CD Health
    interval: 60s
    rules:
      - alert: WoodpeckerServerDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="woodpecker-server"} > 120
        for: 2m
        labels:
          severity: warning
          component: ci
        annotations:
          summary: "ðŸªµ Woodpecker Server DOWN"
          description: "Woodpecker CI server container has not been seen for > 2 minutes."
          runbook: "Check: docker logs woodpecker-server"

      - alert: WoodpeckerAgentDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="woodpecker-agent"} > 120
        for: 2m
        labels:
          severity: warning
          component: ci
        annotations:
          summary: "ðŸ”¨ Woodpecker Agent DOWN"
          description: "Woodpecker CI agent container has not been seen for > 2 minutes. CI builds may queue."
          runbook: "Check: docker logs woodpecker-agent"

      - alert: GiteaDown
        expr: time() - container_last_seen{container_label_com_docker_compose_service="gitea"} > 120
        for: 2m
        labels:
          severity: critical
          component: git
        annotations:
          summary: "ðŸ™ Gitea DOWN - Git repository service unavailable"
          description: "Gitea git server container has not been seen for > 2 minutes. Push/pull operations will fail."
          runbook: "Check: docker logs gitea"
